{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "aitextgen — Train a GPT-2 Text-Generating Model w/ GPU",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c30e83ebde894b15b6e6e8599f483d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f6df3cb188ca45ab8d6df83184662511",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6954bc9295ea4d4caae8d9af8f98afb8",
              "IPY_MODEL_6dfa8f1b71fc47e1a63c58f83eb4291b"
            ]
          }
        },
        "f6df3cb188ca45ab8d6df83184662511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6954bc9295ea4d4caae8d9af8f98afb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c47c476282384182b0e865955f22f223",
            "_dom_classes": [],
            "description": "Fetching checkpoint: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 77,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 77,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c2ff188b3a2432b8b9b8ebfda2ea4c3"
          }
        },
        "6dfa8f1b71fc47e1a63c58f83eb4291b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7429c4addb5f49e98e61b26bac064dae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.05M/? [00:13&lt;00:00, 76.3kit/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87d9d4ec89f74db294c601069c4373ad"
          }
        },
        "c47c476282384182b0e865955f22f223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c2ff188b3a2432b8b9b8ebfda2ea4c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7429c4addb5f49e98e61b26bac064dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87d9d4ec89f74db294c601069c4373ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52aac37ee0cd4e54a38652b3dd31058a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_78e1e937bc8842fcb049ee708f3a2f36",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6d91efdba5e74ed6b4bd57a3f154446a",
              "IPY_MODEL_f15df1437e9f48ad8c648c57224815aa"
            ]
          }
        },
        "78e1e937bc8842fcb049ee708f3a2f36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d91efdba5e74ed6b4bd57a3f154446a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1e953fbba4714e7297e658cb77c22544",
            "_dom_classes": [],
            "description": "Fetching hparams.json: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 90,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 90,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5bf6ee04c5f34d108dddcdef92d34416"
          }
        },
        "f15df1437e9f48ad8c648c57224815aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_635dd618b4a1477b8d7da40054d2a524",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.05M/? [00:04&lt;00:00, 255kit/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f6c274626e64c9d8f1a623b3c48bd5e"
          }
        },
        "1e953fbba4714e7297e658cb77c22544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5bf6ee04c5f34d108dddcdef92d34416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "635dd618b4a1477b8d7da40054d2a524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f6c274626e64c9d8f1a623b3c48bd5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f2788bfb9dc4382b18fe97b0781250e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0b961417d976453e9ed58da9599685ec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4c77e00cf4a0470cb42ec9a0dd9b1531",
              "IPY_MODEL_6802fe01acf14cf9bae066c3cc03a9d1"
            ]
          }
        },
        "0b961417d976453e9ed58da9599685ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c77e00cf4a0470cb42ec9a0dd9b1531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8fae9592587c4e9abc5e98b54a25e2fe",
            "_dom_classes": [],
            "description": "Fetching model.ckpt.data-00000-of-00001: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 497759232,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 497759232,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_06a4493bce13458db947ad430f6072ee"
          }
        },
        "6802fe01acf14cf9bae066c3cc03a9d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8a80a706b0354f8cae8d5166d06f1621",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 498M/? [00:03&lt;00:00, 131Mit/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7516bf808cfc4e03a3de1ab8258fe87b"
          }
        },
        "8fae9592587c4e9abc5e98b54a25e2fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "06a4493bce13458db947ad430f6072ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a80a706b0354f8cae8d5166d06f1621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7516bf808cfc4e03a3de1ab8258fe87b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40f6041a5ec2433ab6da9a55dd41950b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fffb8fb1ecb043deb46455384686ac00",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_954fc1b0cfe2413eb0ee206842effffb",
              "IPY_MODEL_6daa50e792384f0280b332addce1c14d"
            ]
          }
        },
        "fffb8fb1ecb043deb46455384686ac00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "954fc1b0cfe2413eb0ee206842effffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_20584abea47b4b149c4e6b4b3beae39e",
            "_dom_classes": [],
            "description": "Fetching model.ckpt.index: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5215,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5215,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c60a936b0dc41318e29ec4e59897bf2"
          }
        },
        "6daa50e792384f0280b332addce1c14d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d11faad656ad42b4ab7da4b63d61750a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.05M/? [00:09&lt;00:00, 109kit/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5369baaedb0421a81d524ba0dfa531f"
          }
        },
        "20584abea47b4b149c4e6b4b3beae39e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c60a936b0dc41318e29ec4e59897bf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d11faad656ad42b4ab7da4b63d61750a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5369baaedb0421a81d524ba0dfa531f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b26b057750274dd795819d6c2195992a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e3e5361eb9a648ecbfd13049f426559f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7b43bd4c8ebb4adba8a660d53c77e2e8",
              "IPY_MODEL_219c5a93496444e1bfcd15a112fed2be"
            ]
          }
        },
        "e3e5361eb9a648ecbfd13049f426559f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b43bd4c8ebb4adba8a660d53c77e2e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c1e0db5dda574633938d450754d9c04d",
            "_dom_classes": [],
            "description": "Fetching model.ckpt.meta: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 471155,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 471155,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f1f355e3fefa43bca7555be0a6bb0f6b"
          }
        },
        "219c5a93496444e1bfcd15a112fed2be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ead002d5f87044a79869d6da3b022440",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.05M/? [00:00&lt;00:00, 1.31Mit/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b60e4a9f1054a6e8f364863ae37f132"
          }
        },
        "c1e0db5dda574633938d450754d9c04d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f1f355e3fefa43bca7555be0a6bb0f6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ead002d5f87044a79869d6da3b022440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b60e4a9f1054a6e8f364863ae37f132": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c62ba85c8f6b4eb895c784e0f1459254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc702b66f607418581143d6992c3db21",
              "IPY_MODEL_ffef1a2810d24d6c83597e82f80afb44"
            ],
            "layout": "IPY_MODEL_23bda56595c24106b5b4e958b45c4a2d"
          }
        },
        "fc702b66f607418581143d6992c3db21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_632844e1261f4fbb813376cf409ab794",
            "max": 875,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a20953f3e0cf41e483f73d9040c8b3c3",
            "value": 875
          }
        },
        "ffef1a2810d24d6c83597e82f80afb44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c76682b75954b2eae9530341abf3200",
            "placeholder": "​",
            "style": "IPY_MODEL_0b3d97cc5436484288fee203e23c23e3",
            "value": " 875/875 [02:20&lt;00:00,  6.25it/s]"
          }
        },
        "23bda56595c24106b5b4e958b45c4a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "632844e1261f4fbb813376cf409ab794": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a20953f3e0cf41e483f73d9040c8b3c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "9c76682b75954b2eae9530341abf3200": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b3d97cc5436484288fee203e23c23e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17cf9579715443f596220b7361eeb9b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8dbb360ff88340e597648f9971aecf07",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_72ffc57f4cc24526b5d539e6f6a7763a",
              "IPY_MODEL_18f985ba937a4bebaf265f81e6ac4df2"
            ]
          }
        },
        "8dbb360ff88340e597648f9971aecf07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "72ffc57f4cc24526b5d539e6f6a7763a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_67ffb4a0f64a410aa648b98dcbe9cdc3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5410,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5410,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7549fc4528349aeb3053ff15d0ebd0e"
          }
        },
        "18f985ba937a4bebaf265f81e6ac4df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2b2dce991a0b46299359c556ad5bd128",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5410/5410 [00:02&lt;00:00, 2082.41it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b12808543045445bbb4d7a4dfa01bdeb"
          }
        },
        "67ffb4a0f64a410aa648b98dcbe9cdc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7549fc4528349aeb3053ff15d0ebd0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b2dce991a0b46299359c556ad5bd128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b12808543045445bbb4d7a4dfa01bdeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4988de30de624ddbb58ebe6c015b8830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad9cb07760bc4331981b3c5decafd570",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e1977375f3444fbf941e747294465ccd",
              "IPY_MODEL_e51317b61e67420d9466f0e8d00effb6"
            ]
          }
        },
        "ad9cb07760bc4331981b3c5decafd570": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "e1977375f3444fbf941e747294465ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d57f59e3b7294a4fba631410f8df167f",
            "_dom_classes": [],
            "description": "Loss: 2.033 — Avg: 2.123 — GPU Mem: 7291 MB: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 5000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b857a6857234d7e9b87b5fc05c1b16b"
          }
        },
        "e51317b61e67420d9466f0e8d00effb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_da53f8e5e22b402a9a29dbac9d7e998b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5000/5000 [38:00&lt;00:00,  2.19it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4431c3fe2d154cc986fc4778783e1b3f"
          }
        },
        "d57f59e3b7294a4fba631410f8df167f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b857a6857234d7e9b87b5fc05c1b16b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da53f8e5e22b402a9a29dbac9d7e998b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4431c3fe2d154cc986fc4778783e1b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  aitextgen — Train a GPT-2 Text-Generating Model w/ GPU\n",
        "\n",
        "by [Max Woolf](https://minimaxir.com)\n",
        "\n",
        "*Last updated: Jul 5th, 2020*\n",
        "\n",
        "Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Colaboratory** using `aitextgen`!\n",
        "\n",
        "For more about `aitextgen`, you can visit [this GitHub repository](https://github.com/minimaxir/aitextgen) or [read the documentation](https://docs.aitextgen.io/).\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
        "2. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBkpRgBCBS2_",
        "outputId": "af4ef7de-7801-4607-e5dc-51034cb87c05"
      },
      "source": [
        "!pip install transformers==4.0.0\n",
        "!pip install pytorch-lightning==1.0.8\n",
        "\n",
        "!pip install -q aitextgen==0.3.0\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "        format=\"%(asctime)s — %(levelname)s — %(name)s — %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO\n",
        "    )\n",
        "\n",
        "from aitextgen import aitextgen\n",
        "from aitextgen.colab import mount_gdrive, copy_file_from_gdrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 27.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (2019.12.20)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 49.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (20.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==4.0.0) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (2020.12.5)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=8e8b1f96c74c5a394a870ac5ad105cc50036a6f5330b7f06d5f538874d42724b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n",
            "Collecting pytorch-lightning==1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/92/078c5524c875c274ded8a0317ef31a2bb86d02c5c74089ab754d0f12b29c/pytorch_lightning-1.0.8-py3-none-any.whl (561kB)\n",
            "\u001b[K     |████████████████████████████████| 563kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==1.0.8) (2.4.0)\n",
            "Collecting PyYAML>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/5b/bc0b5ab38247bba158504a410112b6c03f153c652734ece1849749e5f518/PyYAML-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (640kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 17.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==1.0.8) (4.41.1)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 15.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==1.0.8) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==1.0.8) (1.7.0+cu101)\n",
            "Collecting fsspec>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/80/72ac0982cc833945fada4b76c52f0f65435ba4d53bc9317d1c70b5f7e7d5/fsspec-0.8.5-py3-none-any.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 13.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.15.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.7.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.32.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (3.12.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (0.36.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (51.3.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (3.3.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (0.10.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.17.2)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.3->pytorch-lightning==1.0.8) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.3->pytorch-lightning==1.0.8) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (3.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (4.6)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (0.4.8)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=1aefdae3e2df08b223e91824ea0cc74d3367d96c01b6fe02f5cfde65e5ab586f\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built future\n",
            "Installing collected packages: PyYAML, future, fsspec, pytorch-lightning\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed PyYAML-5.4.1 fsspec-0.8.5 future-0.18.2 pytorch-lightning-1.0.8\n",
            "\u001b[K     |████████████████████████████████| 573kB 10.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 11.0MB/s \n",
            "\u001b[?25h  Building wheel for aitextgen (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Colaboratory uses a Nvidia P4, an Nvidia T4, or an Nvidia P100 GPU. For finetuning GPT-2 124M, any of these GPUs will be fine, but for text generation, a T4 or a P100 is ideal since they have more VRAM.\n",
        "\n",
        "You can verify which GPU is active by running the cell below. If you want to try for a different GPU, go to **Runtime -> Factory Reset Runtime**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUmTooTW3osf",
        "outputId": "ab52d390-4324-48d4-8fdf-e31357bc12d4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jan 27 13:42:56 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8    10W /  70W |     10MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trRhgNvsH4Wn"
      },
      "source": [
        "## Loading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download and load the GPT-2 model into the GPU. \n",
        "\n",
        "There are several sizes of GPT-2: currently, aitextgen only works with the smallest one:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "\n",
        "Theoretically the \"medium\" model with 355M parameters should also work when using 16-bit floating point numbers using the following code:\n",
        "\n",
        "\n",
        "```python\n",
        "ai = aitextgen(tf_gpt2=\"355M\", to_gpu=True, to_fp16=True)\n",
        "```\n",
        "However as of writing this notebook, there appears to be a problem with output generation when training a model like that.\n",
        "\n",
        "\n",
        "The next cell downloads it from Google's servers and saves it in the Colaboratory VM. If the model has already been downloaded, running this cell will reload it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c30e83ebde894b15b6e6e8599f483d36",
            "f6df3cb188ca45ab8d6df83184662511",
            "6954bc9295ea4d4caae8d9af8f98afb8",
            "6dfa8f1b71fc47e1a63c58f83eb4291b",
            "c47c476282384182b0e865955f22f223",
            "1c2ff188b3a2432b8b9b8ebfda2ea4c3",
            "7429c4addb5f49e98e61b26bac064dae",
            "87d9d4ec89f74db294c601069c4373ad",
            "52aac37ee0cd4e54a38652b3dd31058a",
            "78e1e937bc8842fcb049ee708f3a2f36",
            "6d91efdba5e74ed6b4bd57a3f154446a",
            "f15df1437e9f48ad8c648c57224815aa",
            "1e953fbba4714e7297e658cb77c22544",
            "5bf6ee04c5f34d108dddcdef92d34416",
            "635dd618b4a1477b8d7da40054d2a524",
            "7f6c274626e64c9d8f1a623b3c48bd5e",
            "1f2788bfb9dc4382b18fe97b0781250e",
            "0b961417d976453e9ed58da9599685ec",
            "4c77e00cf4a0470cb42ec9a0dd9b1531",
            "6802fe01acf14cf9bae066c3cc03a9d1",
            "8fae9592587c4e9abc5e98b54a25e2fe",
            "06a4493bce13458db947ad430f6072ee",
            "8a80a706b0354f8cae8d5166d06f1621",
            "7516bf808cfc4e03a3de1ab8258fe87b",
            "40f6041a5ec2433ab6da9a55dd41950b",
            "fffb8fb1ecb043deb46455384686ac00",
            "954fc1b0cfe2413eb0ee206842effffb",
            "6daa50e792384f0280b332addce1c14d",
            "20584abea47b4b149c4e6b4b3beae39e",
            "6c60a936b0dc41318e29ec4e59897bf2",
            "d11faad656ad42b4ab7da4b63d61750a",
            "f5369baaedb0421a81d524ba0dfa531f",
            "b26b057750274dd795819d6c2195992a",
            "e3e5361eb9a648ecbfd13049f426559f",
            "7b43bd4c8ebb4adba8a660d53c77e2e8",
            "219c5a93496444e1bfcd15a112fed2be",
            "c1e0db5dda574633938d450754d9c04d",
            "f1f355e3fefa43bca7555be0a6bb0f6b",
            "ead002d5f87044a79869d6da3b022440",
            "1b60e4a9f1054a6e8f364863ae37f132"
          ]
        },
        "id": "flqSlHjMIeIw",
        "outputId": "e278e8d6-6181-4b02-ad21-9907af6e86e0"
      },
      "source": [
        "ai = aitextgen(tf_gpt2=\"124M\", to_gpu=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/27/2021 13:42:56 — INFO — aitextgen — Downloading the 124M GPT-2 TensorFlow weights/config from Google's servers\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c30e83ebde894b15b6e6e8599f483d36",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Fetching checkpoint', max=77.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52aac37ee0cd4e54a38652b3dd31058a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Fetching hparams.json', max=90.0, style=ProgressStyle(des…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f2788bfb9dc4382b18fe97b0781250e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Fetching model.ckpt.data-00000-of-00001', max=497759232.0…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40f6041a5ec2433ab6da9a55dd41950b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Fetching model.ckpt.index', max=5215.0, style=ProgressSty…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b26b057750274dd795819d6c2195992a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Fetching model.ckpt.meta', max=471155.0, style=ProgressSt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "01/27/2021 13:43:00 — INFO — aitextgen — Converting the 124M GPT-2 TensorFlow weights to PyTorch.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Converting TensorFlow checkpoint from /content/aitextgen/124M\n",
            "Loading TF weight model/h0/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h0/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h0/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h0/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h0/ln_1/b with shape [768]\n",
            "Loading TF weight model/h0/ln_1/g with shape [768]\n",
            "Loading TF weight model/h0/ln_2/b with shape [768]\n",
            "Loading TF weight model/h0/ln_2/g with shape [768]\n",
            "Loading TF weight model/h0/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h0/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h0/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h0/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h1/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h1/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h1/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h1/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h1/ln_1/b with shape [768]\n",
            "Loading TF weight model/h1/ln_1/g with shape [768]\n",
            "Loading TF weight model/h1/ln_2/b with shape [768]\n",
            "Loading TF weight model/h1/ln_2/g with shape [768]\n",
            "Loading TF weight model/h1/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h1/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h1/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h1/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h10/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h10/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h10/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h10/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h10/ln_1/b with shape [768]\n",
            "Loading TF weight model/h10/ln_1/g with shape [768]\n",
            "Loading TF weight model/h10/ln_2/b with shape [768]\n",
            "Loading TF weight model/h10/ln_2/g with shape [768]\n",
            "Loading TF weight model/h10/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h10/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h10/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h10/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h11/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h11/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h11/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h11/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h11/ln_1/b with shape [768]\n",
            "Loading TF weight model/h11/ln_1/g with shape [768]\n",
            "Loading TF weight model/h11/ln_2/b with shape [768]\n",
            "Loading TF weight model/h11/ln_2/g with shape [768]\n",
            "Loading TF weight model/h11/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h11/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h11/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h11/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h2/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h2/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h2/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h2/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h2/ln_1/b with shape [768]\n",
            "Loading TF weight model/h2/ln_1/g with shape [768]\n",
            "Loading TF weight model/h2/ln_2/b with shape [768]\n",
            "Loading TF weight model/h2/ln_2/g with shape [768]\n",
            "Loading TF weight model/h2/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h2/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h2/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h2/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h3/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h3/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h3/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h3/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h3/ln_1/b with shape [768]\n",
            "Loading TF weight model/h3/ln_1/g with shape [768]\n",
            "Loading TF weight model/h3/ln_2/b with shape [768]\n",
            "Loading TF weight model/h3/ln_2/g with shape [768]\n",
            "Loading TF weight model/h3/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h3/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h3/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h3/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h4/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h4/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h4/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h4/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h4/ln_1/b with shape [768]\n",
            "Loading TF weight model/h4/ln_1/g with shape [768]\n",
            "Loading TF weight model/h4/ln_2/b with shape [768]\n",
            "Loading TF weight model/h4/ln_2/g with shape [768]\n",
            "Loading TF weight model/h4/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h4/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h4/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h4/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h5/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h5/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h5/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h5/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h5/ln_1/b with shape [768]\n",
            "Loading TF weight model/h5/ln_1/g with shape [768]\n",
            "Loading TF weight model/h5/ln_2/b with shape [768]\n",
            "Loading TF weight model/h5/ln_2/g with shape [768]\n",
            "Loading TF weight model/h5/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h5/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h5/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h5/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h6/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h6/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h6/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h6/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h6/ln_1/b with shape [768]\n",
            "Loading TF weight model/h6/ln_1/g with shape [768]\n",
            "Loading TF weight model/h6/ln_2/b with shape [768]\n",
            "Loading TF weight model/h6/ln_2/g with shape [768]\n",
            "Loading TF weight model/h6/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h6/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h6/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h6/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h7/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h7/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h7/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h7/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h7/ln_1/b with shape [768]\n",
            "Loading TF weight model/h7/ln_1/g with shape [768]\n",
            "Loading TF weight model/h7/ln_2/b with shape [768]\n",
            "Loading TF weight model/h7/ln_2/g with shape [768]\n",
            "Loading TF weight model/h7/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h7/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h7/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h7/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h8/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h8/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h8/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h8/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h8/ln_1/b with shape [768]\n",
            "Loading TF weight model/h8/ln_1/g with shape [768]\n",
            "Loading TF weight model/h8/ln_2/b with shape [768]\n",
            "Loading TF weight model/h8/ln_2/g with shape [768]\n",
            "Loading TF weight model/h8/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h8/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h8/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h8/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h9/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h9/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h9/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h9/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h9/ln_1/b with shape [768]\n",
            "Loading TF weight model/h9/ln_1/g with shape [768]\n",
            "Loading TF weight model/h9/ln_2/b with shape [768]\n",
            "Loading TF weight model/h9/ln_2/g with shape [768]\n",
            "Loading TF weight model/h9/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h9/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h9/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h9/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/ln_f/b with shape [768]\n",
            "Loading TF weight model/ln_f/g with shape [768]\n",
            "Loading TF weight model/wpe with shape [1024, 768]\n",
            "Loading TF weight model/wte with shape [50257, 768]\n",
            "Initialize PyTorch weight ['h0', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h0', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h0', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h0', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h0', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h0', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h0', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h0', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h0', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h0', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h0', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h0', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h1', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h1', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h1', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h1', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h1', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h1', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h1', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h1', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h1', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h1', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h1', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h1', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h10', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h10', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h10', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h10', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h10', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h10', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h10', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h10', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h10', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h10', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h10', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h10', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h11', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h11', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h11', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h11', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h11', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h11', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h11', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h11', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h11', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h11', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h11', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h11', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h2', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h2', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h2', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h2', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h2', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h2', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h2', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h2', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h2', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h2', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h2', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h2', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h3', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h3', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h3', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h3', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h3', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h3', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h3', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h3', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h3', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h3', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h3', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h3', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h4', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h4', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h4', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h4', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h4', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h4', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h4', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h4', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h4', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h4', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h4', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h4', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h5', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h5', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h5', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h5', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h5', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h5', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h5', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h5', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h5', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h5', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h5', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h5', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h6', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h6', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h6', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h6', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h6', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h6', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h6', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h6', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h6', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h6', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h6', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h6', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h7', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h7', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h7', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h7', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h7', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h7', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h7', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h7', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h7', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h7', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h7', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h7', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h8', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h8', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h8', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h8', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h8', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h8', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h8', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h8', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h8', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h8', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h8', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h8', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h9', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h9', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h9', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h9', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h9', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h9', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h9', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h9', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h9', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h9', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h9', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h9', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['ln_f', 'b']\n",
            "Initialize PyTorch weight ['ln_f', 'g']\n",
            "Initialize PyTorch weight ['wpe']\n",
            "Initialize PyTorch weight ['wte']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Save PyTorch model to aitextgen/pytorch_model.bin\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "01/27/2021 13:43:05 — INFO — aitextgen — Loading 124M GPT-2 model from /aitextgen.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Save configuration file to aitextgen/config.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "01/27/2021 13:43:10 — INFO — aitextgen — Using the default GPT-2 Tokenizer.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puq4iC6vUAHc",
        "outputId": "ddddbfe9-9fbb-44d1-eb20-a212692bd962"
      },
      "source": [
        "mount_gdrive()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE"
      },
      "source": [
        "If your text file is large (>10MB), it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM.\n",
        "\n",
        "Additionally, you may want to consider [compressing the dataset to a cache first](https://docs.aitextgen.io/dataset/) on your local computer, then uploading the resulting `dataset_cache.tar.gz` and setting the `file_name`in the previous cell to that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrgJVyR0bWuc"
      },
      "source": [
        "## Dataset generation\n",
        "We experimented with different kinds of datasets. This notebook comes with three different dataset options:\n",
        "1. Generating a dataset from paper abstracts\n",
        "2. Generating a dataset from full paper texts\n",
        "3. Importing a previously generated dataset\n",
        "\n",
        "Execute the correct cell below depending on which one you'd like to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elySus-r__CQ"
      },
      "source": [
        "## Dataset generation (abstracts)\n",
        "The following cells will generate a TokenSet from the econstore abstracts and save the cache to be reused for futures training runs.\n",
        "\n",
        "If you already have generated a dataset, you can skip these two cells and instead load it directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5gtCgMAxgtg"
      },
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "dir = \"/content/drive/MyDrive/NLP_scientific-text-generation/json\"\n",
        "\n",
        "abstracts = []\n",
        "count = 1000\n",
        "i = 0\n",
        "\n",
        "for f_name in os.listdir(dir):\n",
        "  if f_name.endswith(\".json\"):\n",
        "    path = os.path.join(dir, f_name)\n",
        "    with open(path, \"r\") as f:\n",
        "      data = json.load(f)\n",
        "      is_english = False\n",
        "      abstract = \"\"\n",
        "      for obj in data[\"metadata\"]:\n",
        "        if obj[\"key\"] == \"dc.language.iso\":\n",
        "          if obj[\"value\"] == \"eng\":\n",
        "            is_english = True\n",
        "          else:\n",
        "            break\n",
        "        elif obj[\"key\"] == \"dc.description.abstract\":\n",
        "          abstract = obj[\"value\"]\n",
        "          if is_english:\n",
        "            break\n",
        "      \n",
        "      if is_english:\n",
        "        abstracts.append(abstract)\n",
        "\n",
        "    # ensure we get exactly the amount of samples required\n",
        "    if len(abstracts) >= count:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "c62ba85c8f6b4eb895c784e0f1459254",
            "fc702b66f607418581143d6992c3db21",
            "ffef1a2810d24d6c83597e82f80afb44",
            "23bda56595c24106b5b4e958b45c4a2d",
            "632844e1261f4fbb813376cf409ab794",
            "a20953f3e0cf41e483f73d9040c8b3c3",
            "9c76682b75954b2eae9530341abf3200",
            "0b3d97cc5436484288fee203e23c23e3"
          ]
        },
        "id": "EXVQVerx1BWE",
        "outputId": "c6e6d5c9-a7af-4d20-e69f-675026c154e0"
      },
      "source": [
        "from aitextgen.TokenDataset import TokenDataset\n",
        "dataset = TokenDataset(texts = abstracts)\n",
        "dataset.save()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/18/2021 14:22:57 — INFO — aitextgen.TokenDataset — Encoding 875 texts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c62ba85c8f6b4eb895c784e0f1459254",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=875.0), HTML(value='')), layout=Layout(di…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "01/18/2021 14:22:57 — INFO — aitextgen.TokenDataset — Caching and compressing dataset to dataset_cache.tar.gz\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1ANQBzLpPeY"
      },
      "source": [
        "## Dataset generation (full texts)\n",
        "This code imports a file containing full text papers formatted to contain one paragraph per line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "17cf9579715443f596220b7361eeb9b2",
            "8dbb360ff88340e597648f9971aecf07",
            "72ffc57f4cc24526b5d539e6f6a7763a",
            "18f985ba937a4bebaf265f81e6ac4df2",
            "67ffb4a0f64a410aa648b98dcbe9cdc3",
            "b7549fc4528349aeb3053ff15d0ebd0e",
            "2b2dce991a0b46299359c556ad5bd128",
            "b12808543045445bbb4d7a4dfa01bdeb"
          ]
        },
        "id": "i14IDHl8pfr4",
        "outputId": "ee4492fd-4d99-4881-d0ce-e53fa36c83db"
      },
      "source": [
        "from aitextgen.TokenDataset import TokenDataset\n",
        "dataset = TokenDataset(\"/content/drive/MyDrive/NLP_scientific-text-generation/full_texts_merged.txt\", line_by_line=False)\n",
        "dataset.save()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17cf9579715443f596220b7361eeb9b2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=5410.0), HTML(value='')), layout=Layout(d…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "01/27/2021 13:44:07 — INFO — aitextgen.TokenDataset — Encoding 5,410 sets of tokens from /content/drive/MyDrive/NLP_scientific-text-generation/full_texts_merged.txt.\n",
            "01/27/2021 13:44:09 — INFO — aitextgen.TokenDataset — Caching and compressing dataset to dataset_cache.tar.gz\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLxzs2lL48QQ"
      },
      "source": [
        "## Load existing dataset\n",
        "If you'd like to use a previously generated dataset, you can execute this cell to load it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tlR_Zmu45-8",
        "outputId": "36be4aa0-f197-426d-e010-e0c16c67779d"
      },
      "source": [
        "from aitextgen.TokenDataset import TokenDataset\n",
        "dataset = TokenDataset(\"dataset_cache.tar.gz\", from_cache=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/18/2021 14:26:59 — INFO — aitextgen.TokenDataset — TokenDataset containing 180,583 subsets loaded via cache.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2 in aitextgen. It runs for `num_steps`, and a progress bar will appear to show training progress, current loss (the lower the better the model), and average loss (to give a sense on loss trajectory).\n",
        "\n",
        "The model will be saved every `save_every` steps in `trained_model` by default, and when training completes. If you mounted your Google Drive, the model will _also_ be saved there in a unique folder.\n",
        "\n",
        "The training might time out after 4ish hours; if you did not mount to Google Drive, make sure you end training and save the results so you don't lose them! (if this happens frequently, you may want to consider using [Colab Pro](https://colab.research.google.com/signup))\n",
        "\n",
        "Important parameters for `train()`:\n",
        "\n",
        "- **`line_by_line`**: Set this to `True` if the input text file is a single-column CSV, with one record per row. aitextgen will automatically process it optimally.\n",
        "- **`from_cache`**: If you compressed your dataset locally (as noted in the previous section) and are using that cache file, set this to `True`.\n",
        "- **`num_steps`**: Number of steps to train the model for.\n",
        "- **`generate_every`**: Interval of steps to generate example text from the model; good for qualitatively validating training.\n",
        "- **`save_every`**: Interval of steps to save the model: the model will be saved in the VM to `/trained_model`.\n",
        "- **`save_gdrive`**: Set this to `True` to copy the model to a unique folder in your Google Drive, if you have mounted it in the earlier cells\n",
        "\n",
        "Here are other important parameters for `train()` that are useful but you likely do not need to change.\n",
        "\n",
        "- **`learning_rate`**: Learning rate of the model training.\n",
        "- **`batch_size`**: Batch size of the model training; setting it too high will cause the GPU to go OOM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798,
          "referenced_widgets": [
            "4988de30de624ddbb58ebe6c015b8830",
            "ad9cb07760bc4331981b3c5decafd570",
            "e1977375f3444fbf941e747294465ccd",
            "e51317b61e67420d9466f0e8d00effb6",
            "d57f59e3b7294a4fba631410f8df167f",
            "0b857a6857234d7e9b87b5fc05c1b16b",
            "da53f8e5e22b402a9a29dbac9d7e998b",
            "4431c3fe2d154cc986fc4778783e1b3f"
          ]
        },
        "id": "aeXshJM-Cuaf",
        "outputId": "33849da6-6493-44d2-d731-c36bb7a5e7c6"
      },
      "source": [
        "ai.train(dataset,\n",
        "         line_by_line=False,\n",
        "         from_cache=False,\n",
        "         num_steps=5000,\n",
        "         generate_every=1000,\n",
        "         save_every=1000,\n",
        "         save_gdrive=True,\n",
        "         learning_rate=1e-4,\n",
        "         batch_size=1,\n",
        "         )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "01/27/2021 13:44:10 — INFO — lightning — GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "01/27/2021 13:44:10 — INFO — lightning — TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "01/27/2021 13:44:10 — INFO — lightning — LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4988de30de624ddbb58ebe6c015b8830",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=5000.0), HTML(value='')), layout=Layout(d…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m1,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "sustainable development and sustainability has been a priority for the National Strategy, and in particular, the energy policy. The Strategy is based on the following assumptions: that the sustainable development requires a balance between the development and economic growth and the conservation of natural resources, and that this requires an economic balance of production and consumption. The Strategy is fully supportive of sustainable development, and requires the following measures:\n",
            "The objective of the project is to support the development of the energy sector, including the development of new energy sources (oil, gas, natural gas, etc.), production of energy, distribution of energy resources and the promotion of the development of energy supply systems, and\n",
            "The project is to support the development of technologies for the extraction of natural gas and renewable resources and to provide additional support for the development of the energy in the energy system.\n",
            "The objectives of the National Strategy are established on the basis of the following objectives: to promote the economic development, to support the development of the energy sector, to encourage the use of renewable energy, to support the development of the energy development through the development of energy efficiency and to promote the use of the energy in all sectors of the energy system, to promote the economic development through the development of energy efficiency, to support the development of the energy\n",
            "==========\n",
            "\u001b[1m2,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "of the European Union’s national security state, the main role of the EU is represented by the EU, with a strategic role, but also a military role, with a civilian and support role, and also a commercial one. Both the EU and EU have a substantial role in the internal security market, as they have a considerable number of active security partners, and are in continuous dialogue with each other, and cooperation and cooperation is based on mutual understanding and cooperation, and not risk. The European Union is the most important security partner of the European Union, as it has the support of the European Union Member States and the European Union for the protection of its territory and of its people. The main European Union member states are:\n",
            "the European Union, for the protection of its territory and of the member states, is a vital security partner, and also a member state of the European Union. It is obliged to communicate and to ensure the integration of its citizens in the global security environment and also of its economy. The European Union is a member state of the European Union, therefore it has the legal and institutional duty to respect the European norms of behavior and its own territorial and territorial policies, and to implement them effectively, as part of the European strategy of the protection of its\n",
            "==========\n",
            "\u001b[1m3,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "i am interested in the economic performance of the tourism industry, as in the last ten years, the economic growth is expected, the growth rates are expected, and the quality of life. The tourism industry is well established in Europe. The highest volume of tourism receipts in the last ten years are represented by the tourism industry in Romania. Tourism industry in Romania consists mainly of tourist arrivals and tourists coming from the European countries. The main sectors of tourism industry are tourism, hotel, hotels and souvenir industry. The tourism industry is very competitive in the tourism sector, with an average annual growth rate of between 20% and 60% in the total economy. In the tourism industry, the average annual growth rate from the period 2008-2011 is not very high, but it is still a factor considered very important considering the importance of business as well as the growth in the tourism sector. Tourism is a field in which there are many variables which influence the performance of the tour industry. Tourism is a field in which the demand for tourism products is increasing, but this demand is not always the same for tourism products. Tourism product development is the product development of a tourism product, but it is a factor considered important by the general manager of the company. In Romania, tourism is considered a field in\n",
            "==========\n",
            "\u001b[1m4,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m4,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "BEIJING - THE SCALE OF THE EU RELATIONS: A GLOBALIAN INTERFERENCE\n",
            "The relationship between EU and China appears to have evolved since the beginning of the XXI. The interdependence appears as the most intense political confrontation between the EU and China in the presence of Russia. A visible aspect of the interdependence is the mutual fear of the neighbours of the former communist states, who see the EU as a threat to their own existence and their security by blocking Chinese imports from the East. This fear seems justified. The Chinese government is determined to keep its distance from the EU and the Chinese market, and to use military means at all costs. The Chinese ambassador, for example, has publicly expressed support for the use of a chemical weapon against a Syrian airfield, and for the use of a hydrogen-powered submarine for strategic purposes in order to limit the Iran nuclear and ballistic missile defence system. The Chinese ambassador, Zhang Dejiang, has explained that the only real risk of rupture is if the US does not recognise China as a key investor. The two countries have also been close friends for a long time, and in March 2010, the Chinese ambassador was invited to the UN General Assembly meeting by the Chinese prime minister, Zhang Gaoli.\n",
            "==========\n",
            "\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            " or an absolute maximum value (e.g., 50% in the product range) and an absolute minimum value (e.g., 50% in the model range) and a maximum value (e.g., 100% in the model range) at the product-product interface. In the following table, we show the results of applying the new stochastic tests to the stochastic model with the maximum and the absolute value at the product-product interface. Table 4. Test-Runs Dependent Variable: Parameter Measure Dependent Variable: Targeted Variable: Results\n",
            "Note: **P<0.05’\n",
            "Source: The authors have presented the results at the 1% level for the two-tailed (p-tailed) significance levels. The values in parentheses are calculated using the following formula:\n",
            "Note: **p<0.05’, **p<0.01’, **p<0.05’, **p<0.01’, ***p<0.01’, **p<0.05’, ***p<0.01’, ***p<0.05’, ***p<0.01’, ***p<0.\n",
            "==========\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "01/27/2021 14:22:05 — INFO — aitextgen — Saving trained model pytorch_model.bin to /trained_model\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L"
      },
      "source": [
        "\n",
        "## Load a Trained Model\n",
        "\n",
        "Running the next cell will copy the `pytorch_model.bin` and the `config.json`file from the specified folder in Google Drive into the Colaboratory VM. (If no `from_folder` is specified, it assumes the two files are located at the root level of your Google Drive)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "source": [
        "from_folder = None\n",
        "\n",
        "for file in [\"pytorch_model.bin\", \"config.json\"]:\n",
        "  if from_folder:\n",
        "    copy_file_from_gdrive(file, from_folder)\n",
        "  else:\n",
        "    copy_file_from_gdrive(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV"
      },
      "source": [
        "The next cell will allow you to load the retrained model + metadata necessary to generate text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "-fxL77nvAMAX",
        "outputId": "368bd05a-711f-4775-9e06-ba1fa6582a80"
      },
      "source": [
        "ai = aitextgen(model=\"pytorch_model.bin\", config=\"config.json\", to_gpu=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "05/17/2020 20:27:21 — INFO — aitextgen — Loading GPT-2 model from provided pytorch_model.bin.\n",
            "05/17/2020 20:27:26 — INFO — aitextgen — Using the default GPT-2 Tokenizer.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate()` without any parameters generates a single text from the loaded model to the console."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RNY6RBI9LmL",
        "outputId": "05394687-4781-4a78-9e7d-e6bb2a873643"
      },
      "source": [
        "ai.generate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[0m>The proliferation of storage infrastructure in the EU in the past decade has limited the ability to develop alternative district heating and cooling systems. Energy infrastructure innovation centres are sparse and feature limited specialization and competition. Large companies tend to follow the 'closed innovation' model where R&D activities are concentrated within an organization, and focus on incremental innovations while lagging in radical innovations in cogeneration and trigeneration. Under these conditions, short-term planning dominates, while mid-term planning is virtually non-existent. The paper concludes with recommended measures to support the innovative development of Russian heating companies that can be split into institutional and corporate recommendations. The first group concerns stimulating competition in the heat supply market and creating a stable legal and investment environment. The second group calls for technological modernization, development of long-term corporate strategies that include investment programmes, systematic analysis of the best international practices for innovative development, and the formation of partner networks involving foreign innovative, consulting, and research centres.<|endoftext|>The authors solve the IS puzzle for the G7 countries. They find that five of the G7 countries have the expected significant negative relationship between the output gap and the real-rate gap; the time series of the remaining two show material deviation from expected IS-curve behavior\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = ai.generate_one()`\n",
        "\n",
        "You can also pass in a `prompt` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `n`. You can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 50 for `batch_size` to avoid going OOM).\n",
        "\n",
        "Other optional-but-helpful parameters for `ai.generate()` and friends:\n",
        "\n",
        "*  **`max_length`**: Number of tokens to generate (default 256, you can generate up to 1024 tokens with GPT-2, but it will be _much_ slower)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76e6cc1-51c2-43c9-95ec-687fb038e25c"
      },
      "source": [
        "ai.generate(n=10,\n",
        "            batch_size=5,\n",
        "            prompt=\n",
        "            \"\"\"[QUESTION]:What is the difference between climate change and global warming? \n",
        "[ANSWER]:Global warming refers to the long-term warming of the planet. Climate change encompasses global warming, but refers to the broader range of changes that are happening to our planet, including rising sea levels; shrinking mountain glaciers; accelerating ice melt in Greenland, Antarctica and the Arctic; and shifts in flower/plant blooming times.\n",
        "\n",
        "[QUESTION]:What is the greenhouse effect? \n",
        "[ANSWER]:The greenhouse effect is the way in which heat is trapped close to the surface of the Earth by greenhouse gases.\n",
        "\n",
        "[QUESTION]:How much does nuclear power affect world climate change?\n",
        "[ANSWER]:\"\"\",\n",
        "            max_length=256,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m[QUESTION]:What is the difference between climate change and global warming? \n",
            "[ANSWER]:Global warming refers to the long-term warming of the planet. Climate change encompasses global warming, but refers to the broader range of changes that are happening to our planet, including rising sea levels; shrinking mountain glaciers; accelerating ice melt in Greenland, Antarctica and the Arctic; and shifts in flower/plant blooming times.\n",
            "\n",
            "[QUESTION]:What is the greenhouse effect? \n",
            "[ANSWER]:The greenhouse effect is the way in which heat is trapped close to the surface of the Earth by greenhouse gases.\n",
            "\n",
            "[QUESTION]:How much does nuclear power affect world climate change?\n",
            "[ANSWER]:\u001b[0mU.S. and other developed countries have put into the forefront of efforts to fight climate change. For example, China, the world leader in the use of energy sources with a lower mass of carbon, has committed to significantly increase its contribution to climate change by using more efficient and less fossil energy sources. Thus, China is strongly involved in the fight against climate change. However, outside of the two great powers, the relationship between energy use and climate change remain distant. For example, China leads the world in terms of energy use per capita, while\n",
            "==========\n",
            "\u001b[1m[QUESTION]:What is the difference between climate change and global warming? \n",
            "[ANSWER]:Global warming refers to the long-term warming of the planet. Climate change encompasses global warming, but refers to the broader range of changes that are happening to our planet, including rising sea levels; shrinking mountain glaciers; accelerating ice melt in Greenland, Antarctica and the Arctic; and shifts in flower/plant blooming times.\n",
            "\n",
            "[QUESTION]:What is the greenhouse effect? \n",
            "[ANSWER]:The greenhouse effect is the way in which heat is trapped close to the surface of the Earth by greenhouse gases.\n",
            "\n",
            "[QUESTION]:How much does nuclear power affect world climate change?\n",
            "[ANSWER]:\u001b[0mThe main problem with using the term \"world temperature change’s\" is that it does not refer to the actual location of the source of energy. The closest I could come to describing the effects of an effect is in analogy to the one above, but I think it would be best to stick with the simpler definition.\n",
            "[ANSWER]:The term \"climate change’s\" has the same meaning as the rest of the article. The reason for this is that the two terms are interdependent, and it is often difficult for me\n",
            "==========\n",
            "\u001b[1m[QUESTION]:What is the difference between climate change and global warming? \n",
            "[ANSWER]:Global warming refers to the long-term warming of the planet. Climate change encompasses global warming, but refers to the broader range of changes that are happening to our planet, including rising sea levels; shrinking mountain glaciers; accelerating ice melt in Greenland, Antarctica and the Arctic; and shifts in flower/plant blooming times.\n",
            "\n",
            "[QUESTION]:What is the greenhouse effect? \n",
            "[ANSWER]:The greenhouse effect is the way in which heat is trapped close to the surface of the Earth by greenhouse gases.\n",
            "\n",
            "[QUESTION]:How much does nuclear power affect world climate change?\n",
            "[ANSWER]:\u001b[0m The share of greenhouse gas in the share of total GHG in the world is almost twice as high as the share of GHG in the non-state GHG-equivalent (non-tariff) countries [ANSWER]: The share of GHG in the world is much lower than the share of GHG in the non-state economies [ANSWER]: According to the UNEP (2013) GHG emission is divided into two groups: the highest intensity group, the ENIEST group, which includes energy use and the GHG\n",
            "==========\n",
            "\u001b[1m[QUESTION]:What is the difference between climate change and global warming? \n",
            "[ANSWER]:Global warming refers to the long-term warming of the planet. Climate change encompasses global warming, but refers to the broader range of changes that are happening to our planet, including rising sea levels; shrinking mountain glaciers; accelerating ice melt in Greenland, Antarctica and the Arctic; and shifts in flower/plant blooming times.\n",
            "\n",
            "[QUESTION]:What is the greenhouse effect? \n",
            "[ANSWER]:The greenhouse effect is the way in which heat is trapped close to the surface of the Earth by greenhouse gases.\n",
            "\n",
            "[QUESTION]:How much does nuclear power affect world climate change?\n",
            "[ANSWER]:\u001b[0m About half of the energy from nuclear power is spent on fossil fuels. The rest is spent on other nonrenewable resources.\n",
            "The discussion about the scientific literature’s relationship between the subject and the results it’s usually associated with, is fraught with uncertainty and even death. The lack of a consistent relationship between the level of scientific uncertainty and the magnitude of the uncertainty varies between scientific papers and the results they draw. For example, the uncertainty of the results in a given situation can often be explained by the lack of control exercised by\n",
            "==========\n",
            "\u001b[1m[QUESTION]:What is the difference between climate change and global warming? \n",
            "[ANSWER]:Global warming refers to the long-term warming of the planet. Climate change encompasses global warming, but refers to the broader range of changes that are happening to our planet, including rising sea levels; shrinking mountain glaciers; accelerating ice melt in Greenland, Antarctica and the Arctic; and shifts in flower/plant blooming times.\n",
            "\n",
            "[QUESTION]:What is the greenhouse effect? \n",
            "[ANSWER]:The greenhouse effect is the way in which heat is trapped close to the surface of the Earth by greenhouse gases.\n",
            "\n",
            "[QUESTION]:How much does nuclear power affect world climate change?\n",
            "[ANSWER]:\u001b[0m Nuclear power is the type of energy technology generally available for use. The reason for this is simple: computers are not designed for this type of energy. The only problem is that the energy density of a rock is not sensitive to the presence and development of any other energy density (energy spillage, density of water, or flow) on the rock. The ability of a technology to store energy is not important. The only way to deal with this issue is to heat the rock with a pyrolimide fuel cell. Heat can be concentrated in one\n",
            "==========\n",
            "\u001b[1m[QUESTION]:What is the difference between climate change and global warming? \n",
            "[ANSWER]:Global warming refers to the long-term warming of the planet. Climate change encompasses global warming, but refers to the broader range of changes that are happening to our planet, including rising sea levels; shrinking mountain glaciers; accelerating ice melt in Greenland, Antarctica and the Arctic; and shifts in flower/plant blooming times.\n",
            "\n",
            "[QUESTION]:What is the greenhouse effect? \n",
            "[ANSWER]:The greenhouse effect is the way in which heat is trapped close to the surface of the Earth by greenhouse gases.\n",
            "\n",
            "[QUESTION]:How much does nuclear power affect world climate change?\n",
            "[ANSWER]:\u001b[0mNuclear power is generally considered as a cleaner energy option, but there are limits to its use for power generation and consumption. Heat is a basic element of any system’s operation. Heat is also generally expected to be an inert greenhouse gas.\n",
            "Specific CO2 emissions are important for determining whether there is a change in temperature. For example, if greenhouse gas is 1.0% of the total energy mix, and temperature changes are not important (for example, if the temperature of a city is set at room temperature), it is not important\n",
            "==========\n",
            "\u001b[1m[QUESTION]:What is the difference between climate change and global warming? \n",
            "[ANSWER]:Global warming refers to the long-term warming of the planet. Climate change encompasses global warming, but refers to the broader range of changes that are happening to our planet, including rising sea levels; shrinking mountain glaciers; accelerating ice melt in Greenland, Antarctica and the Arctic; and shifts in flower/plant blooming times.\n",
            "\n",
            "[QUESTION]:What is the greenhouse effect? \n",
            "[ANSWER]:The greenhouse effect is the way in which heat is trapped close to the surface of the Earth by greenhouse gases.\n",
            "\n",
            "[QUESTION]:How much does nuclear power affect world climate change?\n",
            "[ANSWER]:\u001b[0mThe nuclear power plant is, by far, the most dangerous element of using nuclear power. It causes, in large measure, irreversible destruction of the entire planet.\n",
            "The list of questions above leads to the following difficulties: 1) The question is not clear. The last question is, if not, clear. 2) The question is not clear. The answer is, if anything, quite\n",
            "the same. 3) The question is not clear. The answer may be quite precisely\n",
            "the same as in the previous paragraphs. 4) The question is\n",
            "==========\n",
            "\u001b[1m[QUESTION]:What is the difference between climate change and global warming? \n",
            "[ANSWER]:Global warming refers to the long-term warming of the planet. Climate change encompasses global warming, but refers to the broader range of changes that are happening to our planet, including rising sea levels; shrinking mountain glaciers; accelerating ice melt in Greenland, Antarctica and the Arctic; and shifts in flower/plant blooming times.\n",
            "\n",
            "[QUESTION]:What is the greenhouse effect? \n",
            "[ANSWER]:The greenhouse effect is the way in which heat is trapped close to the surface of the Earth by greenhouse gases.\n",
            "\n",
            "[QUESTION]:How much does nuclear power affect world climate change?\n",
            "[ANSWER]:\u001b[0mRadiation is the process by which greenhouse gases are reduced to a low carbon value.\n",
            "[ANSWER]: Massdrop is how much of the energy in our planet is concentrated inside the first-lowest temperature range. Massdrop is what happens when a rock is hit by a blast of heat energy. Heat energy is the heat energy that is trapped in the rock. Massdrop is how much of this energy is concentrated in a secondlowest temperature range. Massdrop is how much of it is actually absorbed by the surface of the secondlowest\n",
            "==========\n",
            "\u001b[1m[QUESTION]:What is the difference between climate change and global warming? \n",
            "[ANSWER]:Global warming refers to the long-term warming of the planet. Climate change encompasses global warming, but refers to the broader range of changes that are happening to our planet, including rising sea levels; shrinking mountain glaciers; accelerating ice melt in Greenland, Antarctica and the Arctic; and shifts in flower/plant blooming times.\n",
            "\n",
            "[QUESTION]:What is the greenhouse effect? \n",
            "[ANSWER]:The greenhouse effect is the way in which heat is trapped close to the surface of the Earth by greenhouse gases.\n",
            "\n",
            "[QUESTION]:How much does nuclear power affect world climate change?\n",
            "[ANSWER]:\u001b[0mThe problem with keeping a temperature constant over long periods of time can arise from various sources. Some of these sources include: changes in climate changes due to climate\n",
            "[ANSWER]: changes in climate changes due to climate changes can vary greatly from one state of the world to another. Some of these changes can be found in the variability in temperature of precipitation; changes in precipitation and durdle precipitation due to changes in climate\n",
            "[ANSWER]: Changing temperature in a region changes the behaviour of hydrological processes. Therefore, a change in temperature in\n",
            "==========\n",
            "\u001b[1m[QUESTION]:What is the difference between climate change and global warming? \n",
            "[ANSWER]:Global warming refers to the long-term warming of the planet. Climate change encompasses global warming, but refers to the broader range of changes that are happening to our planet, including rising sea levels; shrinking mountain glaciers; accelerating ice melt in Greenland, Antarctica and the Arctic; and shifts in flower/plant blooming times.\n",
            "\n",
            "[QUESTION]:What is the greenhouse effect? \n",
            "[ANSWER]:The greenhouse effect is the way in which heat is trapped close to the surface of the Earth by greenhouse gases.\n",
            "\n",
            "[QUESTION]:How much does nuclear power affect world climate change?\n",
            "[ANSWER]:\u001b[0mThe main aspect of uncertainty in our current debate is the uncertainty in the relationship between temperature and temperature. Although climate change has already been discussed in previous debates, there is no general definition of what causes climate change. There are many different ways of thinking about it. Some of them are more like a chain of command and some more like a pendulum. In the end, the two most common ways of thinking are:\n",
            "John Pezzey published in his book “The Case Against the Global Economy” (2002) and in his new\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E"
      },
      "source": [
        "# LICENSE\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2020 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}