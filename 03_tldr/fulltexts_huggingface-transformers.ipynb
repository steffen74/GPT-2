{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GTP2_FineTuning and TDLR Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QEn1WecUkUvY",
        "GHLvD-uEkbJI",
        "fSTy6TTPJhGA",
        "QJOiwV2ekLRw",
        "nXNQEf7Yrly6",
        "z3ZJoqtnkjKB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "50876ad384f240cfafed0163fda26936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_de55b63e05304fc4bdc683d00fb72e8f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_290ad72421f949919ab5f34ed65eff4e",
              "IPY_MODEL_6d01014ecc614eb590c8eab1f66c67fc"
            ]
          }
        },
        "39287dfad94e4afbaa0286a21fc0e987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1aca273c67c3460b9e7d699f59ee40a8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f6551bb4071246caaf1915912b0e6a24",
              "IPY_MODEL_ffb27e27a6a24ace90490b36fccf31f3"
            ]
          }
        },
        "3d39a6732dff4c419528e66a419e51ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_676d9eafe36b4bfa935ea50093667f38",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aa944cbc03a24ee6bfae87c7e29fa855",
              "IPY_MODEL_36d30b6317b5423b86c33421d0c9b43b"
            ]
          }
        },
        "aa6545f76d0a4da0bb98ab4b0cfd83c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4c98f6016ff3489985eb0562148982f3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6dc842fe9358448cb424f1bc0c71bb9f",
              "IPY_MODEL_3cf99deee61945099879582c27b6d555"
            ]
          }
        },
        "8e3da21f97244b9087046b6c7d68a878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d8f10d11831146889ca2c4bdb474258b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1374d581fdb245999db392212ffe3c12",
              "IPY_MODEL_15305aac8982472ab22aa47bde674ecb"
            ]
          }
        },
        "0bbb900cd6c84c91bba1ebdf8280a1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ce6420e1fd1a4ab0a02dee9c7c4697e4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2a1d5a770b4847778241957fbbd8722a",
              "IPY_MODEL_158897d72355404590bd9ebd91c96f4b"
            ]
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-3CyESydUAq"
      },
      "source": [
        "#Colab preparation & Data preparation\r\n",
        "\r\n",
        "\r\n",
        "1.   Mount Google Drive\r\n",
        "2.   Import & Prepare Fulltexts\r\n",
        "3.   Create Training, Validation, and Test Datasets\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEn1WecUkUvY"
      },
      "source": [
        "###1. Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIVMJ2ISYuJ1",
        "outputId": "b9bf2f49-d298-46a0-8f76-c2259fe4d694"
      },
      "source": [
        "# Mounting GoogleDrive to the content folder\r\n",
        "from google.colab import drive\r\n",
        "import os\r\n",
        "\r\n",
        "drive.mount('/content/gdrive')  # Mounting GoogleDrive to the content folder"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HETVDf5_RMit"
      },
      "source": [
        "# Change Working Directory\r\n",
        "working_dir = 'NLP_scientific-text-generation/'\r\n",
        "os.chdir('/content/gdrive/MyDrive/'+working_dir)  # Changing the working directory to the project folder on GoogleDrive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHLvD-uEkbJI"
      },
      "source": [
        "###2. Import and Prepare Fulltexts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C9DP_BFZBdd"
      },
      "source": [
        "import re\r\n",
        "\r\n",
        "dir = \"prep/02_fulltexts-climate-change\"\r\n",
        "papers = []\r\n",
        "\r\n",
        "# Definition of the Beginning of Sample (BOS) and End of Sample (EOS) Tokens\r\n",
        "bos_token = '<BOS>'\r\n",
        "eos_token = '<EOS>'\r\n",
        "\r\n",
        "for f_name in os.listdir(dir):\r\n",
        "  path = os.path.join(dir, f_name)\r\n",
        "  with open(path, \"r\") as f:\r\n",
        "    f_text = ''.join(f.readlines()) # Fulltext as a single string\r\n",
        "    f_text = re.sub(r'\\n(?!\\n)(?<!\\n\\n)', ' ', f_text) # Replace carriage returns if no carriage return follows immediatly with white spave (to remove line breaks due to scanning)\r\n",
        "    f_text = bos_token + f_text + eos_token\r\n",
        "    papers.append(f_text)\r\n",
        "  "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67HXDvlJZdYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc344c8-1f4c-4663-be27-96ccce1e8881"
      },
      "source": [
        "#Create a dataframe with each fulltext in a single row\r\n",
        "import pandas as pd\r\n",
        "data = (papers) \r\n",
        "df = pd.DataFrame(data)\r\n",
        "df.columns = ['sample']\r\n",
        "#df = df.reset_index()\r\n",
        "\r\n",
        "# Visual Check of the data\r\n",
        "print(df)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                sample\n",
            "0    <BOS>Introduction A new trend of research in p...\n",
            "1    <BOS>U.S. – E.U. ECONOMIC RELATIONS IN THE CON...\n",
            "2    <BOS>JEL Classification: F18; Q34; Q56; Q57.\\n...\n",
            "3    <BOS>Excellence fosters convergence in higher ...\n",
            "4    <BOS>Introduction\\n\\n1.1\\n\\nThe transition to ...\n",
            "..                                                 ...\n",
            "143  <BOS>With varying degrees of intensity, each o...\n",
            "144  <BOS> Second query\\n\\nTOPIC (electric OR hybri...\n",
            "145  <BOS>\\n\\n1 Introduction Companies are more tha...\n",
            "146  <BOS>Introduction\\n\\nThe UN’s Sustainable Deve...\n",
            "147  <BOS>Introduction\\n\\nSustainable functioning o...\n",
            "\n",
            "[148 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSTy6TTPJhGA"
      },
      "source": [
        "###3. Create Training, Validation, and Test Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqlggerbcfwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e8783c-362e-41ae-fb9e-ecae5817d134"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "import re\r\n",
        "\r\n",
        "# Splitting Train-, Validation-, & Testdata\r\n",
        "train_test_ratio = 0.9  #Proportion of training data\r\n",
        "train_valid_ratio = 7/9 #Proportion of validation data\r\n",
        "\r\n",
        "# Splitting Test Data (10%) from the Total Dataset\r\n",
        "df_full_train, df_test = train_test_split(df, train_size = train_test_ratio, random_state = 1)\r\n",
        "\r\n",
        "# Splitting the Remaining Data into Test and Validation Dataset\r\n",
        "df_train, df_valid = train_test_split(df_full_train, train_size = train_valid_ratio, random_state = 1)\r\n",
        "\r\n",
        "# Visual Check of the Training Data\r\n",
        "print(df_train)\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                sample\n",
            "22   <BOS> 1. Introduction Analyses of farm efficie...\n",
            "96   <BOS> Background Developed and developing econ...\n",
            "106  <BOS>clearly stands out. Marchand and Walker (...\n",
            "67   <BOS>Introduction\\n\\nIn the modern society, to...\n",
            "48   <BOS>JEL Classification: F15, F16, F41, F02\\n\\...\n",
            "..                                                 ...\n",
            "27   <BOS> Introduction Sustainability has become a...\n",
            "137  <BOS> 9891\\n\\n1. Introduction Sustainability o...\n",
            "87   <BOS>Economic Policy in the Wake of the Crisis...\n",
            "23   <BOS>JEL Classification: Q42; Q48; F10; F5.\\n\\...\n",
            "124  <BOS> Background Current issues and challenges...\n",
            "\n",
            "[103 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVQRQ82EoUq1"
      },
      "source": [
        "# Save Datasets to Individual Files\r\n",
        "df_train.to_csv(\"train.txt\", index=False, header=False, encoding='utf-8')\r\n",
        "df_valid.to_csv(\"valid.txt\", index=False, header=False, encoding='utf-8')\r\n",
        "df_test.to_csv(\"test.txt\", index=False, header=False, encoding='utf-8')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJOiwV2ekLRw"
      },
      "source": [
        "##Get the huggingface transformers library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mafkz0KCeKpJ",
        "outputId": "ec72dadf-27fd-4194-ab78-d9571f6324d2"
      },
      "source": [
        "!pip install datasets\r\n",
        "!pip install transformers\r\n",
        "#Clone gitgub repository to get the required python scripts\r\n",
        "!git clone https://github.com/huggingface/transformers.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.6/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from datasets) (0.8)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.2.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESLpPynEdjJO",
        "outputId": "1b223b16-6ca8-4403-826c-12a7810f58e5"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jan 26 12:33:40 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8     8W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_UNbotJkZAQ"
      },
      "source": [
        "# Fine-Tuning of the GPT-2 Model\r\n",
        "Different model sizes can be used by changing \"--model_name_or_path gpt2\"\r\n",
        "GTP-2 models from huggingface can be found [here](https://huggingface.co/transformers/pretrained_models.html). \r\n",
        "\r\n",
        "GPT-2 models (OpenAI):\r\n",
        "*   gpt2(12-layer, 768-hidden, 12-heads, 117M parameters)\r\n",
        "*   gpt2-medium (24-layer, 1024-hidden, 16-heads, 345M parameters)\r\n",
        "*   gpt2-large (36-layer, 1280-hidden, 20-heads, 774M parameters)\r\n",
        "*   gpt2-xl (48-layer, 1600-hidden, 25-heads, 1558M parameters)\r\n",
        "Distill GPT by huggingface:\r\n",
        "*   distilgpt2\r\n",
        "Model distilled from the GPT-2 (gpt2) model and checkpoints )6-layer, 768-hidden, 12-heads, 82M parameters).\r\n",
        "\r\n",
        "The large and xl version might not run on a colab because of RAM issues even when a batch size of one is used.\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "50876ad384f240cfafed0163fda26936",
            "39287dfad94e4afbaa0286a21fc0e987",
            "3d39a6732dff4c419528e66a419e51ec",
            "aa6545f76d0a4da0bb98ab4b0cfd83c5",
            "8e3da21f97244b9087046b6c7d68a878",
            "0bbb900cd6c84c91bba1ebdf8280a1ad"
          ]
        },
        "id": "IpQDR51pdhse",
        "outputId": "5fe29141-7821-46bf-a25d-3018800cb4ba"
      },
      "source": [
        "#Trains the model. Be careful with the batch_size when using larger models or datasets.\r\n",
        "%run \"prep/transformers/examples/language-modeling/run_clm.py\" \\\r\n",
        "    --model_name_or_path gpt2 \\\r\n",
        "    --train_file \"train.txt\" \\\r\n",
        "    --validation_file \"valid.txt\" \\\r\n",
        "    --do_train \\\r\n",
        "    --do_eval \\\r\n",
        "    --output_dir \"output/\" \\\r\n",
        "    --per_device_train_batch_size=1 \\\r\n",
        "    --per_device_eval_batch_size=1 \\\r\n",
        "    --learning_rate 5e-5 \\\r\n",
        "    --num_train_epochs=6 \\\r\n",
        "    --overwrite_output_dir"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/26/2021 12:34:19 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "01/26/2021 12:34:19 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir=output/, overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=EvaluationStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=1, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=6.0, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_steps=0, logging_dir=runs/Jan26_12-34-19_c494915f7425, logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=output/, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, _n_gpu=1)\n",
            "Using custom data configuration default\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset text/default-5d1e496d89f8f224 (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/text/default-5d1e496d89f8f224/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50876ad384f240cfafed0163fda26936",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39287dfad94e4afbaa0286a21fc0e987",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-5d1e496d89f8f224/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab. Subsequent calls will reuse this data.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO|configuration_utils.py:445] 2021-01-26 12:34:20,832 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "[INFO|configuration_utils.py:481] 2021-01-26 12:34:20,834 >> Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.2.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:445] 2021-01-26 12:34:20,939 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "[INFO|configuration_utils.py:481] 2021-01-26 12:34:20,940 >> Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.2.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1766] 2021-01-26 12:34:21,260 >> loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "[INFO|tokenization_utils_base.py:1766] 2021-01-26 12:34:21,260 >> loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|tokenization_utils_base.py:1766] 2021-01-26 12:34:21,261 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "[INFO|modeling_utils.py:1027] 2021-01-26 12:34:21,428 >> loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "[INFO|modeling_utils.py:1143] 2021-01-26 12:34:26,089 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:1152] 2021-01-26 12:34:26,090 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "[WARNING|tokenization_utils_base.py:3197] 2021-01-26 12:34:26,101 >> Token indices sequence length is longer than the specified maximum sequence length for this model (1445 > 1024). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d39a6732dff4c419528e66a419e51ec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa6545f76d0a4da0bb98ab4b0cfd83c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e3da21f97244b9087046b6c7d68a878",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bbb900cd6c84c91bba1ebdf8280a1ad",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO|trainer.py:442] 2021-01-26 12:34:44,961 >> The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: .\n",
            "[INFO|trainer.py:442] 2021-01-26 12:34:44,962 >> The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: .\n",
            "[INFO|trainer.py:791] 2021-01-26 12:34:44,972 >> ***** Running training *****\n",
            "[INFO|trainer.py:792] 2021-01-26 12:34:44,972 >>   Num examples = 984\n",
            "[INFO|trainer.py:793] 2021-01-26 12:34:44,973 >>   Num Epochs = 6\n",
            "[INFO|trainer.py:794] 2021-01-26 12:34:44,974 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:795] 2021-01-26 12:34:44,974 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "[INFO|trainer.py:796] 2021-01-26 12:34:44,975 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:797] 2021-01-26 12:34:44,977 >>   Total optimization steps = 5904\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='5904' max='5904' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5904/5904 57:12, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.471400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.327300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>3.056000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>3.039700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>2.861900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>2.786600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>2.691900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>2.675800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>2.566900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>2.589700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>2.514300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO|trainer.py:1344] 2021-01-26 12:39:25,322 >> Saving model checkpoint to output/checkpoint-500\n",
            "[INFO|configuration_utils.py:300] 2021-01-26 12:39:25,641 >> Configuration saved in output/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:817] 2021-01-26 12:39:27,982 >> Model weights saved in output/checkpoint-500/pytorch_model.bin\n",
            "[INFO|trainer.py:1344] 2021-01-26 12:44:15,642 >> Saving model checkpoint to output/checkpoint-1000\n",
            "[INFO|configuration_utils.py:300] 2021-01-26 12:44:15,889 >> Configuration saved in output/checkpoint-1000/config.json\n",
            "[INFO|modeling_utils.py:817] 2021-01-26 12:44:18,356 >> Model weights saved in output/checkpoint-1000/pytorch_model.bin\n",
            "[INFO|trainer.py:1344] 2021-01-26 12:49:06,474 >> Saving model checkpoint to output/checkpoint-1500\n",
            "[INFO|configuration_utils.py:300] 2021-01-26 12:49:06,664 >> Configuration saved in output/checkpoint-1500/config.json\n",
            "[INFO|modeling_utils.py:817] 2021-01-26 12:49:09,391 >> Model weights saved in output/checkpoint-1500/pytorch_model.bin\n",
            "[INFO|trainer.py:1344] 2021-01-26 12:53:59,712 >> Saving model checkpoint to output/checkpoint-2000\n",
            "[INFO|configuration_utils.py:300] 2021-01-26 12:53:59,844 >> Configuration saved in output/checkpoint-2000/config.json\n",
            "[INFO|modeling_utils.py:817] 2021-01-26 12:54:02,395 >> Model weights saved in output/checkpoint-2000/pytorch_model.bin\n",
            "[INFO|trainer.py:1344] 2021-01-26 12:58:52,678 >> Saving model checkpoint to output/checkpoint-2500\n",
            "[INFO|configuration_utils.py:300] 2021-01-26 12:58:52,830 >> Configuration saved in output/checkpoint-2500/config.json\n",
            "[INFO|modeling_utils.py:817] 2021-01-26 12:58:55,588 >> Model weights saved in output/checkpoint-2500/pytorch_model.bin\n",
            "[INFO|trainer.py:1344] 2021-01-26 13:03:46,233 >> Saving model checkpoint to output/checkpoint-3000\n",
            "[INFO|configuration_utils.py:300] 2021-01-26 13:03:46,365 >> Configuration saved in output/checkpoint-3000/config.json\n",
            "[INFO|modeling_utils.py:817] 2021-01-26 13:03:48,956 >> Model weights saved in output/checkpoint-3000/pytorch_model.bin\n",
            "[INFO|trainer.py:1344] 2021-01-26 13:08:37,769 >> Saving model checkpoint to output/checkpoint-3500\n",
            "[INFO|configuration_utils.py:300] 2021-01-26 13:08:37,953 >> Configuration saved in output/checkpoint-3500/config.json\n",
            "[INFO|modeling_utils.py:817] 2021-01-26 13:08:40,433 >> Model weights saved in output/checkpoint-3500/pytorch_model.bin\n",
            "[INFO|trainer.py:1344] 2021-01-26 13:13:27,765 >> Saving model checkpoint to output/checkpoint-4000\n",
            "[INFO|configuration_utils.py:300] 2021-01-26 13:13:27,923 >> Configuration saved in output/checkpoint-4000/config.json\n",
            "[INFO|modeling_utils.py:817] 2021-01-26 13:13:30,548 >> Model weights saved in output/checkpoint-4000/pytorch_model.bin\n",
            "[INFO|trainer.py:1344] 2021-01-26 13:18:18,564 >> Saving model checkpoint to output/checkpoint-4500\n",
            "[INFO|configuration_utils.py:300] 2021-01-26 13:18:18,732 >> Configuration saved in output/checkpoint-4500/config.json\n",
            "[INFO|modeling_utils.py:817] 2021-01-26 13:18:21,525 >> Model weights saved in output/checkpoint-4500/pytorch_model.bin\n",
            "[INFO|trainer.py:1344] 2021-01-26 13:23:08,955 >> Saving model checkpoint to output/checkpoint-5000\n",
            "[INFO|configuration_utils.py:300] 2021-01-26 13:23:09,137 >> Configuration saved in output/checkpoint-5000/config.json\n",
            "[INFO|modeling_utils.py:817] 2021-01-26 13:23:11,900 >> Model weights saved in output/checkpoint-5000/pytorch_model.bin\n",
            "[INFO|trainer.py:1344] 2021-01-26 13:28:00,302 >> Saving model checkpoint to output/checkpoint-5500\n",
            "[INFO|configuration_utils.py:300] 2021-01-26 13:28:00,444 >> Configuration saved in output/checkpoint-5500/config.json\n",
            "[INFO|modeling_utils.py:817] 2021-01-26 13:28:03,384 >> Model weights saved in output/checkpoint-5500/pytorch_model.bin\n",
            "[INFO|trainer.py:953] 2021-01-26 13:31:58,014 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "[INFO|trainer.py:1344] 2021-01-26 13:31:58,067 >> Saving model checkpoint to output/\n",
            "[INFO|configuration_utils.py:300] 2021-01-26 13:31:58,245 >> Configuration saved in output/config.json\n",
            "[INFO|modeling_utils.py:817] 2021-01-26 13:32:00,927 >> Model weights saved in output/pytorch_model.bin\n",
            "01/26/2021 13:32:01 - INFO - __main__ -   ***** Train results *****\n",
            "01/26/2021 13:32:01 - INFO - __main__ -     epoch = 6.0\n",
            "01/26/2021 13:32:01 - INFO - __main__ -     total_flos = 4513951496798208\n",
            "01/26/2021 13:32:01 - INFO - __main__ -     train_runtime = 3433.0402\n",
            "01/26/2021 13:32:01 - INFO - __main__ -     train_samples_per_second = 1.72\n",
            "01/26/2021 13:32:02 - INFO - __main__ -   *** Evaluate ***\n",
            "[INFO|trainer.py:1536] 2021-01-26 13:32:02,125 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:1537] 2021-01-26 13:32:02,125 >>   Num examples = 273\n",
            "[INFO|trainer.py:1538] 2021-01-26 13:32:02,128 >>   Batch size = 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='273' max='273' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [273/273 00:44]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "01/26/2021 13:32:46 - INFO - __main__ -   ***** Eval results *****\n",
            "01/26/2021 13:32:46 - INFO - __main__ -     perplexity = 32.8289058882148\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f6LtvPAx4AD"
      },
      "source": [
        "#Generation of TL;DRs\r\n",
        "1. Definition of the Test Abstracts\r\n",
        "2. Definition of the Prompts for One-Shot and Few-Shot Learning\r\n",
        "3. Generation of the Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXNQEf7Yrly6"
      },
      "source": [
        "### 1. Definition of the Test Abstracts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ33jJsnr63C"
      },
      "source": [
        "test_abstract_1 = \"Greenhouse gas emissions have significantly altered global climate, and will continue to do so in the future. Increases in the frequency, duration, and/or severity of drought and heat stress associated with climate change could fundamentally alter the composition, structure, and biogeography of forests in many regions. Of particular concern are potential increases in tree mortality associated with climate-induced physiological stress and interactions with other climate-mediated processes such as insect outbreaks and wildfire. Despite this risk, existing projections of tree mortality are based on models that lack functionally realistic mortality mechanisms, and there has been no attempt to track observations of climate-driven tree mortality globally. Here we present the first global assessment of recent tree mortality attributed to drought and heat stress. Although episodic mortality occurs in the absence of climate change, studies compiled here suggest that at least some of the world's forested ecosystems already may be responding to climate change and raise concern that forests may become increasingly vulnerable to higher background tree mortality rates and die-off in response to future warming and drought, even in environments that are not normally considered water-limited. This further suggests risks to ecosystem services, including the loss of sequestered forest carbon and associated atmospheric feedbacks. Our review also identifies key information gaps and scientific uncertainties that currently hinder our ability to predict tree mortality in response to climate change and emphasizes the need for a globally coordinated observation system. Overall, our review reveals the potential for amplified tree mortality due to drought and heat in forests worldwide.\"\r\n",
        "test_abstract_2 = \"The world's forests influence climate through physical, chemical, and biological processes that affect planetary energetics, the hydrologic cycle, and atmospheric composition. These complex and nonlinear forest-atmosphere interactions can dampen or amplify anthropogenic climate change. Tropical, temperate, and boreal reforestation and afforestation attenuate global warming through carbon sequestration. Biogeophysical feedbacks can enhance or diminish this negative climate forcing. Tropical forests mitigate warming through evaporative cooling, but the low albedo of boreal forests is a positive climate forcing. The evaporative effect of temperate forests is unclear. The net climate forcing from these and other processes is not known. Forests are under tremendous pressure from global change. Interdisciplinary science that integrates knowledge of the many interacting climate services of forests with the impacts of global change is necessary to identify and understand as yet unexplored feedbacks in the Earth system and the potential of forests to mitigate climate change.\"\r\n",
        "test_abstract_3 = \"The paper summarizes the current knowledge about the impact of livestock sector on climate change. The main sources of greenhouse gas (GHG) emissions from livestock are described and the contribution of livestock sector to the global GHG emissions is presented on the basis of the latest results obtained from the scientific research. The most recent mitigation strategies for reducing greenhouse gas emissions from livestock sector are also discussed. The paper aims to provide a general overview of an emergent environmental issue such as the impact of livestock sector on climate change. While the paper is easy to understand for non-expert readers, it may also be a relevant reference point for academic researchers and for policy makers aimed at achieving the sustainability of livestock/food sector.\"\r\n",
        "test_abstract_4 = \"Feeding a growing global population in a changing climate presents a significant challenge to society. The projected yields of crops under a range of agricultural and climatic scenarios are needed to assess food security prospects. Previous meta-analyses have summarized climate change impacts and adaptive potential as a function of temperature, but have not examined uncertainty, the timing of impacts, or the quantitative effectiveness of adaptation. Here we develop a new data set of more than 1,700 published simulations to evaluate yield impacts of climate change and adaptation. Without adaptation, losses in aggregate production are expected for wheat, rice and maize in both temperate and tropical regions by 2 °C of local warming. Crop-level adaptations increase simulated yields by an average of 7–15%, with adaptations more effective for wheat and rice than maize. Yield losses are greater in magnitude for the second half of the century than for the first. Consensus on yield decreases in the second half of the century is stronger in tropical than temperate regions, yet even moderate warming may reduce temperate crop yields in many locations. Although less is known about interannual variability than mean yields, the available data indicate that increases in yield variability are likely.\"\r\n",
        "test_abstract_5 = \"The effects of climate change on biodiversity are increasingly well documented, and many methods have been developed to assess species' vulnerability to climatic changes, both ongoing and projected in the coming decades. To minimize global biodiversity losses, conservationists need to identify those species that are likely to be most vulnerable to the impacts of climate change. In this Review, we summarize different currencies used for assessing species' climate change vulnerability. We describe three main approaches used to derive these currencies (correlative, mechanistic and trait-based), and their associated data requirements, spatial and temporal scales of application and modelling methods. We identify strengths and weaknesses of the approaches and highlight the sources of uncertainty inherent in each method that limit projection reliability. Finally, we provide guidance for conservation practitioners in selecting the most appropriate approach(es) for their planning needs and highlight priority areas for further assessments.\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3ZJoqtnkjKB"
      },
      "source": [
        "### 2. Definition of the Prompts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm38jl6dhAQa"
      },
      "source": [
        "abstract_1 = \"Causal attribution of recent biological trends to climate change is complicated because non-climatic influences dominate local, short-term biological changes. Any underlying signal from climate change is likely to be revealed by analyses that seek systematic trends across diverse species and geographic regions; however, debates within the Intergovernmental Panel on Climate Change (IPCC) reveal several definitions of a ‘systematic trend’. Here, we explore these differences, apply diverse analyses to more than 1,700 species, and show that recent biological trends match climate change predictions. Global meta-analyses documented significant range shifts averaging 6.1 km per decade towards the poles (or metres per decade upward), and significant mean advancement of spring events by 2.3 days per decade. We define a diagnostic fingerprint of temporal and spatial ‘sign-switching’ responses uniquely predicted by twentieth century climate trends. Among appropriate long-term/large-scale/multi-species data sets, this diagnostic fingerprint was found for 279 species. This suite of analyses generates ‘very high confidence’ (as laid down by the IPCC) that climate change is already affecting living systems.\"\r\n",
        "tldr_1 = \"Climate change predictions are confirmed by the collective change in distribution of species, and the change in timing of biological events.\"\r\n",
        "\r\n",
        "abstract_2 = \"Significantly more carbon is stored in the world's soils—including peatlands, wetlands and permafrost—than is present in the atmosphere. Disagreement exists, however, regarding the effects of climate change on global soil carbon stocks. If carbon stored belowground is transferred to the atmosphere by a warming-induced acceleration of its decomposition, a positive feedback to climate change would occur. Conversely, if increases of plant-derived carbon inputs to soils exceed increases in decomposition, the feedback would be negative. Despite much research, a consensus has not yet emerged on the temperature sensitivity of soil carbon decomposition. Unravelling the feedback effect is particularly difficult, because the diverse soil organic compounds exhibit a wide range of kinetic properties, which determine the intrinsic temperature sensitivity of their decomposition. Moreover, several environmental constraints obscure the intrinsic temperature sensitivity of substrate decomposition, causing lower observed ‘apparent’ temperature sensitivity, and these constraints may, themselves, be sensitive to climate.\"\r\n",
        "tldr_2 = \"Soil carbon decomposition may be sensitive to climate, but the amount of decomposition is constrained by other factors.\"\r\n",
        "\r\n",
        "abstract_3 = \"Climate change over the past ∼30 years has produced numerous shifts in the distributions and abundances of species and has been implicated in one species-level extinction. Using projections of species' distributions for future climate scenarios, we assess extinction risks for sample regions that cover some 20% of the Earth's terrestrial surface. Exploring three approaches in which the estimated probability of extinction shows a power-law relationship with geographical range size, we predict, on the basis of mid-range climate-warming scenarios for 2050, that 15–37% of species in our sample of regions and taxa will be ‘committed to extinction’. When the average of the three methods and two dispersal scenarios is taken, minimal climate-warming scenarios produce lower projections of species committed to extinction (∼18%) than mid-range (∼24%) and maximum-change (∼35%) scenarios. These estimates show the importance of rapid implementation of technologies to decrease greenhouse gas emissions and strategies for carbon sequestration.\"\r\n",
        "tldr_3 = \"Using predictions of future climate, the authors predict that if greenhouse gases continue to increase, 15-37% of species will be committed to extinction.\"\r\n",
        "\r\n",
        "\r\n",
        "# One-Shot Prompt\r\n",
        "os_prompt = \"Abstract:\\n\" + abstract_1 + \"\\nTL;DR:\\n\" + tldr_1 + \"\\n\\nAbstract:\\n\"\r\n",
        "\r\n",
        "# Few-Shot Prompt (2-Shot)\r\n",
        "fs_prompt = \"Abstract:\\n\" + abstract_1 + \"\\nTL;DR:\\n\" + tldr_1 + \"\\n\\nAbstract:\\n\" + abstract_2 + \"\\nTL;DR:\\n\" + tldr_2 + \"\\n\\nAbstract:\\n\" + abstract_3 + \"\\nTL;DR:\\n\" + tldr_3 + \"\\n\\nAbstract:\\n\"\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qiTsX5gyriB"
      },
      "source": [
        "### 3. Generation of the TL;DR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7pmpjVUq0UD"
      },
      "source": [
        "For each test abstract five TL;DRs are generated using a one-shot approach and five using a few-shot approach.\r\n",
        "\r\n",
        "`run_generation` allows to set the following arguments/flags for the generation:  \r\n",
        "```\r\n",
        "run_generation.py [-h]\r\n",
        "--model_type MODEL_TYPE \\  \r\n",
        "--model_name_or_path MODEL_NAME_OR_PATH  \r\n",
        "[--prompt PROMPT \\]  \r\n",
        "[--length LENGTH \\]  \r\n",
        "[--stop_token STOP_TOKEN \\]  \r\n",
        "[--temperature TEMPERATURE \\]  \r\n",
        "[--repetition_penalty REPETITION_PENALTY]  \r\n",
        "[--k K \\]  \r\n",
        "[--p P \\]  \r\n",
        "[--prefix PREFIX \\]  \r\n",
        "[--padding_text PADDING_TEXT \\]  \r\n",
        "[--xlm_language XLM_LANGUAGE \\]  \r\n",
        "[--seed SEED \\]  \r\n",
        "[--no_cuda \\]  \r\n",
        "[--num_return_sequences NUM_RETURN_SEQUENCES \\]  \r\n",
        "[--fp16]\r\n",
        "```\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33NP0uZ5p0yH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "575f74e3-c4cd-4816-b07d-75e6294e1f90"
      },
      "source": [
        "# Test Abstract 1 with One-Shot-TLDR-Generation\r\n",
        "prompt = os_prompt + test_abstract_1 + \"\\nTL;DR:\\n\"\r\n",
        "\r\n",
        "%run \"transformers/examples/text-generation/run_generation.py\" \\\r\n",
        "--model_type gpt2 \\\r\n",
        "--model_name_or_path \"output/\" \\\r\n",
        "--prompt \"$prompt\" \\\r\n",
        "--length 100 \\\r\n",
        "--stop_token \"\\.\" \\\r\n",
        "--temperature .7 \\\r\n",
        "--k 50 \\\r\n",
        "--num_return_sequences 5"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/26/2021 13:38:20 - WARNING - __main__ -   device: cuda, n_gpu: 1, 16-bits training: False\n",
            "[INFO|tokenization_utils_base.py:1685] 2021-01-26 13:38:20,036 >> Model name 'output/' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'output/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "[INFO|tokenization_utils_base.py:1718] 2021-01-26 13:38:20,038 >> Didn't find file output/added_tokens.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1718] 2021-01-26 13:38:20,040 >> Didn't find file output/tokenizer.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1764] 2021-01-26 13:38:20,041 >> loading file output/vocab.json\n",
            "[INFO|tokenization_utils_base.py:1764] 2021-01-26 13:38:20,042 >> loading file output/merges.txt\n",
            "[INFO|tokenization_utils_base.py:1764] 2021-01-26 13:38:20,043 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1764] 2021-01-26 13:38:20,043 >> loading file output/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1764] 2021-01-26 13:38:20,044 >> loading file output/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1764] 2021-01-26 13:38:20,045 >> loading file None\n",
            "[INFO|configuration_utils.py:443] 2021-01-26 13:38:20,197 >> loading configuration file output/config.json\n",
            "[INFO|configuration_utils.py:481] 2021-01-26 13:38:20,199 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.2.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:1025] 2021-01-26 13:38:20,200 >> loading weights file output/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:1143] 2021-01-26 13:38:25,385 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:1152] 2021-01-26 13:38:25,387 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at output/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "01/26/2021 13:38:25 - INFO - __main__ -   Namespace(device=device(type='cuda'), fp16=False, k=50, length=100, model_name_or_path='output/', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prefix='', prompt=\"Abstract:\\nCausal attribution of recent biological trends to climate change is complicated because non-climatic influences dominate local, short-term biological changes. Any underlying signal from climate change is likely to be revealed by analyses that seek systematic trends across diverse species and geographic regions; however, debates within the Intergovernmental Panel on Climate Change (IPCC) reveal several definitions of a ‘systematic trend’. Here, we explore these differences, apply diverse analyses to more than 1,700 species, and show that recent biological trends match climate change predictions. Global meta-analyses documented significant range shifts averaging 6.1\\u2009km per decade towards the poles (or metres per decade upward), and significant mean advancement of spring events by 2.3 days per decade. We define a diagnostic fingerprint of temporal and spatial ‘sign-switching’ responses uniquely predicted by twentieth century climate trends. Among appropriate long-term/large-scale/multi-species data sets, this diagnostic fingerprint was found for 279 species. This suite of analyses generates ‘very high confidence’ (as laid down by the IPCC) that climate change is already affecting living systems.\\nTL;DR:\\nClimate change predictions are confirmed by the collective change in distribution of species, and the change in timing of biological events.\\n\\nAbstract:\\nGreenhouse gas emissions have significantly altered global climate, and will continue to do so in the future. Increases in the frequency, duration, and/or severity of drought and heat stress associated with climate change could fundamentally alter the composition, structure, and biogeography of forests in many regions. Of particular concern are potential increases in tree mortality associated with climate-induced physiological stress and interactions with other climate-mediated processes such as insect outbreaks and wildfire. Despite this risk, existing projections of tree mortality are based on models that lack functionally realistic mortality mechanisms, and there has been no attempt to track observations of climate-driven tree mortality globally. Here we present the first global assessment of recent tree mortality attributed to drought and heat stress. Although episodic mortality occurs in the absence of climate change, studies compiled here suggest that at least some of the world's forested ecosystems already may be responding to climate change and raise concern that forests may become increasingly vulnerable to higher background tree mortality rates and die-off in response to future warming and drought, even in environments that are not normally considered water-limited. This further suggests risks to ecosystem services, including the loss of sequestered forest carbon and associated atmospheric feedbacks. Our review also identifies key information gaps and scientific uncertainties that currently hinder our ability to predict tree mortality in response to climate change and emphasizes the need for a globally coordinated observation system. Overall, our review reveals the potential for amplified tree mortality due to drought and heat in forests worldwide.\\nTL;DR:\\n\", repetition_penalty=1.0, seed=42, stop_token='\\\\.', temperature=0.7, xlm_language='')\n",
            "[WARNING|generation_utils.py:828] 2021-01-26 13:38:25,607 >> Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "=== GENERATED SEQUENCE 1 ===\n",
            "Abstract:\n",
            "Causal attribution of recent biological trends to climate change is complicated because non-climatic influences dominate local, short-term biological changes. Any underlying signal from climate change is likely to be revealed by analyses that seek systematic trends across diverse species and geographic regions; however, debates within the Intergovernmental Panel on Climate Change (IPCC) reveal several definitions of a ‘systematic trend’. Here, we explore these differences, apply diverse analyses to more than 1,700 species, and show that recent biological trends match climate change predictions. Global meta-analyses documented significant range shifts averaging 6.1 km per decade towards the poles (or metres per decade upward), and significant mean advancement of spring events by 2.3 days per decade. We define a diagnostic fingerprint of temporal and spatial ‘sign-switching’ responses uniquely predicted by twentieth century climate trends. Among appropriate long-term/large-scale/multi-species data sets, this diagnostic fingerprint was found for 279 species. This suite of analyses generates ‘very high confidence’ (as laid down by the IPCC) that climate change is already affecting living systems.\n",
            "TL;DR:\n",
            "Climate change predictions are confirmed by the collective change in distribution of species, and the change in timing of biological events.\n",
            "\n",
            "Abstract:\n",
            "Greenhouse gas emissions have significantly altered global climate, and will continue to do so in the future. Increases in the frequency, duration, and/or severity of drought and heat stress associated with climate change could fundamentally alter the composition, structure, and biogeography of forests in many regions. Of particular concern are potential increases in tree mortality associated with climate-induced physiological stress and interactions with other climate-mediated processes such as insect outbreaks and wildfire. Despite this risk, existing projections of tree mortality are based on models that lack functionally realistic mortality mechanisms, and there has been no attempt to track observations of climate-driven tree mortality globally. Here we present the first global assessment of recent tree mortality attributed to drought and heat stress. Although episodic mortality occurs in the absence of climate change, studies compiled here suggest that at least some of the world's forested ecosystems already may be responding to climate change and raise concern that forests may become increasingly vulnerable to higher background tree mortality rates and die-off in response to future warming and drought, even in environments that are not normally considered water-limited. This further suggests risks to ecosystem services, including the loss of sequestered forest carbon and associated atmospheric feedbacks. Our review also identifies key information gaps and scientific uncertainties that currently hinder our ability to predict tree mortality in response to climate change and emphasizes the need for a globally coordinated observation system. Overall, our review reveals the potential for amplified tree mortality due to drought and heat in forests worldwide.\n",
            "TL;DR:\n",
            "‘Climate change is already affecting the distribution of species, ecosystems, and biocapacity in many parts of the world. This will persist and exacerbate as global warming continues to increase, and future global warming will exacerbate these effects.’.doi:10.1038/nature04718.g002.doi:10.1038/nature04718.g003.doi:10.1038/nature04718.g004.doi:10.1038/natur\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "Abstract:\n",
            "Causal attribution of recent biological trends to climate change is complicated because non-climatic influences dominate local, short-term biological changes. Any underlying signal from climate change is likely to be revealed by analyses that seek systematic trends across diverse species and geographic regions; however, debates within the Intergovernmental Panel on Climate Change (IPCC) reveal several definitions of a ‘systematic trend’. Here, we explore these differences, apply diverse analyses to more than 1,700 species, and show that recent biological trends match climate change predictions. Global meta-analyses documented significant range shifts averaging 6.1 km per decade towards the poles (or metres per decade upward), and significant mean advancement of spring events by 2.3 days per decade. We define a diagnostic fingerprint of temporal and spatial ‘sign-switching’ responses uniquely predicted by twentieth century climate trends. Among appropriate long-term/large-scale/multi-species data sets, this diagnostic fingerprint was found for 279 species. This suite of analyses generates ‘very high confidence’ (as laid down by the IPCC) that climate change is already affecting living systems.\n",
            "TL;DR:\n",
            "Climate change predictions are confirmed by the collective change in distribution of species, and the change in timing of biological events.\n",
            "\n",
            "Abstract:\n",
            "Greenhouse gas emissions have significantly altered global climate, and will continue to do so in the future. Increases in the frequency, duration, and/or severity of drought and heat stress associated with climate change could fundamentally alter the composition, structure, and biogeography of forests in many regions. Of particular concern are potential increases in tree mortality associated with climate-induced physiological stress and interactions with other climate-mediated processes such as insect outbreaks and wildfire. Despite this risk, existing projections of tree mortality are based on models that lack functionally realistic mortality mechanisms, and there has been no attempt to track observations of climate-driven tree mortality globally. Here we present the first global assessment of recent tree mortality attributed to drought and heat stress. Although episodic mortality occurs in the absence of climate change, studies compiled here suggest that at least some of the world's forested ecosystems already may be responding to climate change and raise concern that forests may become increasingly vulnerable to higher background tree mortality rates and die-off in response to future warming and drought, even in environments that are not normally considered water-limited. This further suggests risks to ecosystem services, including the loss of sequestered forest carbon and associated atmospheric feedbacks. Our review also identifies key information gaps and scientific uncertainties that currently hinder our ability to predict tree mortality in response to climate change and emphasizes the need for a globally coordinated observation system. Overall, our review reveals the potential for amplified tree mortality due to drought and heat in forests worldwide.\n",
            "TL;DR:\n",
            "The paper is structured as follows: A review of recent studies on the impacts of climate change on ecosystem services. A summary of existing literature. Literature review. Literature review of current knowledge on the impacts of climate change on ecosystem services. Literature review of current knowledge on the impacts of climate change on ecosystem services. Literature review of current knowledge on the impacts of climate change on ecosystem services. Literature review of current knowledge on the impacts of climate change on ecosystem services. Literature review of current knowledge on the impacts o\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "Abstract:\n",
            "Causal attribution of recent biological trends to climate change is complicated because non-climatic influences dominate local, short-term biological changes. Any underlying signal from climate change is likely to be revealed by analyses that seek systematic trends across diverse species and geographic regions; however, debates within the Intergovernmental Panel on Climate Change (IPCC) reveal several definitions of a ‘systematic trend’. Here, we explore these differences, apply diverse analyses to more than 1,700 species, and show that recent biological trends match climate change predictions. Global meta-analyses documented significant range shifts averaging 6.1 km per decade towards the poles (or metres per decade upward), and significant mean advancement of spring events by 2.3 days per decade. We define a diagnostic fingerprint of temporal and spatial ‘sign-switching’ responses uniquely predicted by twentieth century climate trends. Among appropriate long-term/large-scale/multi-species data sets, this diagnostic fingerprint was found for 279 species. This suite of analyses generates ‘very high confidence’ (as laid down by the IPCC) that climate change is already affecting living systems.\n",
            "TL;DR:\n",
            "Climate change predictions are confirmed by the collective change in distribution of species, and the change in timing of biological events.\n",
            "\n",
            "Abstract:\n",
            "Greenhouse gas emissions have significantly altered global climate, and will continue to do so in the future. Increases in the frequency, duration, and/or severity of drought and heat stress associated with climate change could fundamentally alter the composition, structure, and biogeography of forests in many regions. Of particular concern are potential increases in tree mortality associated with climate-induced physiological stress and interactions with other climate-mediated processes such as insect outbreaks and wildfire. Despite this risk, existing projections of tree mortality are based on models that lack functionally realistic mortality mechanisms, and there has been no attempt to track observations of climate-driven tree mortality globally. Here we present the first global assessment of recent tree mortality attributed to drought and heat stress. Although episodic mortality occurs in the absence of climate change, studies compiled here suggest that at least some of the world's forested ecosystems already may be responding to climate change and raise concern that forests may become increasingly vulnerable to higher background tree mortality rates and die-off in response to future warming and drought, even in environments that are not normally considered water-limited. This further suggests risks to ecosystem services, including the loss of sequestered forest carbon and associated atmospheric feedbacks. Our review also identifies key information gaps and scientific uncertainties that currently hinder our ability to predict tree mortality in response to climate change and emphasizes the need for a globally coordinated observation system. Overall, our review reveals the potential for amplified tree mortality due to drought and heat in forests worldwide.\n",
            "TL;DR:\n",
            "‘Climate change impacts the ecosystem through its effects on species and ecosystems.’ (Kumar, P., Walker, C., Brown, C., and Hansen, J.)’s prediction of tree mortality will likely be greatly exaggerated.’ (Kumar, P., Walker, C., Brown, C., and Hansen, J.)’s prediction of tree mortality will likely be greatly exaggerated.’ (Kumar, P., Walker, C., Brown, C., an\n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "Abstract:\n",
            "Causal attribution of recent biological trends to climate change is complicated because non-climatic influences dominate local, short-term biological changes. Any underlying signal from climate change is likely to be revealed by analyses that seek systematic trends across diverse species and geographic regions; however, debates within the Intergovernmental Panel on Climate Change (IPCC) reveal several definitions of a ‘systematic trend’. Here, we explore these differences, apply diverse analyses to more than 1,700 species, and show that recent biological trends match climate change predictions. Global meta-analyses documented significant range shifts averaging 6.1 km per decade towards the poles (or metres per decade upward), and significant mean advancement of spring events by 2.3 days per decade. We define a diagnostic fingerprint of temporal and spatial ‘sign-switching’ responses uniquely predicted by twentieth century climate trends. Among appropriate long-term/large-scale/multi-species data sets, this diagnostic fingerprint was found for 279 species. This suite of analyses generates ‘very high confidence’ (as laid down by the IPCC) that climate change is already affecting living systems.\n",
            "TL;DR:\n",
            "Climate change predictions are confirmed by the collective change in distribution of species, and the change in timing of biological events.\n",
            "\n",
            "Abstract:\n",
            "Greenhouse gas emissions have significantly altered global climate, and will continue to do so in the future. Increases in the frequency, duration, and/or severity of drought and heat stress associated with climate change could fundamentally alter the composition, structure, and biogeography of forests in many regions. Of particular concern are potential increases in tree mortality associated with climate-induced physiological stress and interactions with other climate-mediated processes such as insect outbreaks and wildfire. Despite this risk, existing projections of tree mortality are based on models that lack functionally realistic mortality mechanisms, and there has been no attempt to track observations of climate-driven tree mortality globally. Here we present the first global assessment of recent tree mortality attributed to drought and heat stress. Although episodic mortality occurs in the absence of climate change, studies compiled here suggest that at least some of the world's forested ecosystems already may be responding to climate change and raise concern that forests may become increasingly vulnerable to higher background tree mortality rates and die-off in response to future warming and drought, even in environments that are not normally considered water-limited. This further suggests risks to ecosystem services, including the loss of sequestered forest carbon and associated atmospheric feedbacks. Our review also identifies key information gaps and scientific uncertainties that currently hinder our ability to predict tree mortality in response to climate change and emphasizes the need for a globally coordinated observation system. Overall, our review reveals the potential for amplified tree mortality due to drought and heat in forests worldwide.\n",
            "TL;DR:\n",
            "‘Droughts and heat are leading to massive declines in the carbon-containing biomes of some of the world’s most important climatic regions. Climate change may have a powerful influence on these ecosystems, which could lead to severe consequences on the ecosystem services. This review also highlights the need for a global coordinated assessment of the effects of climate change on ecosystem services.‘(1) This review also highlights the potential for amplified tree mortality due to drought and heat in forests worldwide\n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "Abstract:\n",
            "Causal attribution of recent biological trends to climate change is complicated because non-climatic influences dominate local, short-term biological changes. Any underlying signal from climate change is likely to be revealed by analyses that seek systematic trends across diverse species and geographic regions; however, debates within the Intergovernmental Panel on Climate Change (IPCC) reveal several definitions of a ‘systematic trend’. Here, we explore these differences, apply diverse analyses to more than 1,700 species, and show that recent biological trends match climate change predictions. Global meta-analyses documented significant range shifts averaging 6.1 km per decade towards the poles (or metres per decade upward), and significant mean advancement of spring events by 2.3 days per decade. We define a diagnostic fingerprint of temporal and spatial ‘sign-switching’ responses uniquely predicted by twentieth century climate trends. Among appropriate long-term/large-scale/multi-species data sets, this diagnostic fingerprint was found for 279 species. This suite of analyses generates ‘very high confidence’ (as laid down by the IPCC) that climate change is already affecting living systems.\n",
            "TL;DR:\n",
            "Climate change predictions are confirmed by the collective change in distribution of species, and the change in timing of biological events.\n",
            "\n",
            "Abstract:\n",
            "Greenhouse gas emissions have significantly altered global climate, and will continue to do so in the future. Increases in the frequency, duration, and/or severity of drought and heat stress associated with climate change could fundamentally alter the composition, structure, and biogeography of forests in many regions. Of particular concern are potential increases in tree mortality associated with climate-induced physiological stress and interactions with other climate-mediated processes such as insect outbreaks and wildfire. Despite this risk, existing projections of tree mortality are based on models that lack functionally realistic mortality mechanisms, and there has been no attempt to track observations of climate-driven tree mortality globally. Here we present the first global assessment of recent tree mortality attributed to drought and heat stress. Although episodic mortality occurs in the absence of climate change, studies compiled here suggest that at least some of the world's forested ecosystems already may be responding to climate change and raise concern that forests may become increasingly vulnerable to higher background tree mortality rates and die-off in response to future warming and drought, even in environments that are not normally considered water-limited. This further suggests risks to ecosystem services, including the loss of sequestered forest carbon and associated atmospheric feedbacks. Our review also identifies key information gaps and scientific uncertainties that currently hinder our ability to predict tree mortality in response to climate change and emphasizes the need for a globally coordinated observation system. Overall, our review reveals the potential for amplified tree mortality due to drought and heat in forests worldwide.\n",
            "TL;DR:\n",
            "‘Drought and heat are major drivers of tree mortality in many parts of the world, and their impact on forest ecosystems is poorly understood.‘ (Gibbons, 2008, p. 519) Climate change’s impact on ecosystems is not well understood, and our review highlights the need for a global coordinated effort to understand and prevent climate-related forest mortality in this critical period. (Hastedt, et al., 2015) The climate sensitivity of climate change to the presen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWEeF1QqxR6q"
      },
      "source": [
        "#Save the trained model\r\n",
        "! tar -czf gpt2-tuned.tar.gz output/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}