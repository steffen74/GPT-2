#TL;DR Generation for Scientific Texts with GTP-2
Notebook to generate To-Long;Didn't-Read (TL;DRs) summaries for abstracts or papers using GTP-2. 
Data: Abstracts and fulltexts of 148 papers on climate change from econstor.
Sources for code and notebooks:  
[Huggingface Transformers](https://github.com/huggingface/transformers)

There are also a lot of aricles such as this [Medium post](https://towardsdatascience.com/fine-tuning-gpt2-for-text-generation-using-pytorch-2ee61a4f1ba7) which explain how to use the GPT-2 for text generization. Most of the, however, use older versions of the transformers library.
