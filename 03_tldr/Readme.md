# TL;DR Generation with GTP-2
This folder contains the Python notebooks used to prepare data and fine-tune the GPT-2 as well as the results.  

As des
Data: Abstracts and fulltexts of 148 papers on climate change from econstor.
Sources for code and notebooks:  
[Huggingface Transformers](https://github.com/huggingface/transformers)

There are also a lot of aricles such as this [Medium post](https://towardsdatascience.com/fine-tuning-gpt2-for-text-generation-using-pytorch-2ee61a4f1ba7) which explain how to use the GPT-2 for text generization. Most of the, however, use older versions of the transformers library.
